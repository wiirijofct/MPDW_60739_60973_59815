{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e1f6b4-d475-40ec-91b3-3ecca04a5cc2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generative LLMs: Decoder Models\n",
    "\n",
    "\n",
    "\n",
    "**References:**\n",
    " - Standard language generation: https://huggingface.co/blog/how-to-generate\n",
    " - Constrained language generation: https://huggingface.co/blog/constrained-beam-search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c87a2d-c5f1-425c-8ca7-1a6901f40486",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f0a4ecff560>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 3388997632\n",
      "allocated memory:\t 3218541056\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.47.0\n",
      "pytorch: \t\t 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import transformers\n",
    "from transformers import GenerationConfig, AutoTokenizer, AutoModel, utils, BartForConditionalGeneration \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "utils.logging.set_verbosity_error()  # Remove line to see warnings\n",
    "\n",
    "def cuda_info():\n",
    "    print()\n",
    "    print(\"cuda.is_available: \\t\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda.device_count: \\t\", torch.cuda.device_count())\n",
    "        print(\"cuda.current_device: \\t\", torch.cuda.current_device())\n",
    "        print(\"cuda.device: \\t\\t\", torch.cuda.device(torch.cuda.current_device()))\n",
    "        print()\n",
    "        print(\"cuda.get_device_name: \\t\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "        print(\"total memory: \\t\\t\", torch.cuda.get_device_properties(0).total_memory)\n",
    "        print(\"reserved memory:\\t\", torch.cuda.memory_reserved(0))\n",
    "        print(\"allocated memory:\\t\", torch.cuda.memory_allocated(0))\n",
    "\n",
    "\n",
    "    device = \"cuda:\" + str(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\"\n",
    "    print()\n",
    "    print(\"device name: \\t\\t\", device)\n",
    "    print(\"transformers: \\t\\t\", transformers.__version__)\n",
    "    print(\"pytorch: \\t\\t\", torch.__version__)\n",
    "    \n",
    "def decode_and_print(model, config, sentence):\n",
    "\n",
    "    encoded_input_ids_1 = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids = encoded_input_ids_1,\n",
    "            generation_config = generation_config,\n",
    "            return_dict_in_generate = True,\n",
    "            output_scores = True\n",
    "        )\n",
    "\n",
    "    for s in generation_output.sequences:\n",
    "        output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "        print(output)\n",
    "        \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5306af5-63ea-421c-aa60-5c0b65b649e8",
   "metadata": {},
   "source": [
    "# Decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23969f1f-8cdb-428f-a59b-ce2bb60cf74a",
   "metadata": {},
   "source": [
    "## DialogGPT\n",
    "\n",
    "https://huggingface.co/microsoft/DialoGPT-large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7e62477-fbcc-4ad2-8849-fc40851c5b84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f0ab79f23c0>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 6794772480\n",
      "allocated memory:\t 8519680\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.47.0\n",
      "pytorch: \t\t 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/DialoGPT-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd9001e4-8565-4142-b0c5-421e1dfa6a79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User     : Hello, how are you?\n",
      "DialoGPT : I'm good, you?\n",
      "User     : I'm ok too. Today is a good day.\n",
      "DialoGPT : Good to hear.\n",
      "User     : What will you be doing today?\n",
      "DialoGPT : I'm going to be doing nothing.\n",
      "User     : I like to watch movies with my friends.\n",
      "DialoGPT : That sounds fun.\n",
      "User     : Was Shakespear a good writer?\n",
      "DialoGPT : He was a great writer.\n"
     ]
    }
   ],
   "source": [
    "# Let's chat for 5 lines\n",
    "chat_history_ids = None\n",
    "user_input = [\"Hello, how are you?\", \"I'm ok too. Today is a good day.\", \"What will you be doing today?\", \"I like to watch movies with my friends.\", \"Was Shakespear a good writer?\"]\n",
    "for step in user_input:\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(step + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = new_user_input_ids if chat_history_ids is None else torch.cat([chat_history_ids, new_user_input_ids], dim=-1).to(device)\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"User     : {}\".format(step))\n",
    "    print(\"DialoGPT : {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ae51c-bf0e-492b-8a0d-845e6ea59b32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e788c834-e350-433c-9ea6-bfaeda9f5705",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f0ab792ff50>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 6595543040\n",
      "allocated memory:\t 1633885184\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.47.0\n",
      "pytorch: \t\t 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model. Be sure to set output_attentions=True.\n",
    "# Load BART fine-tuned for summarization on CNN/Daily Mail dataset\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name, output_attentions=True).to(device)\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20062e5b-d18c-472b-9b0b-f1db0c0bce27",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Decoding Strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751a268-03f6-43d9-a83f-fd35867684f6",
   "metadata": {},
   "source": [
    "## Decoding parameters and example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6d0c2b-8783-4b03-9d1b-e4bb4e9a7128",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_new_tokens\": 150,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"temperature\": 0.4,\n",
      "  \"top_k\": 10,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = model.generation_config\n",
    "\n",
    "generation_config.temperature = 0.4\n",
    "generation_config.top_p = 0.8\n",
    "generation_config.top_k = 10\n",
    "generation_config.num_beams = 4\n",
    "generation_config.max_new_tokens = 150\n",
    "\n",
    "print(generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9186b97d-1366-4ad5-a033-e30d5aa75117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.4` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `10` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The spending bill was passed by the House of Representatives. The Senate will vote on the spending bill later this month. The bill is expected to be approved by the Senate on Thursday.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create ids of encoded input vectors\n",
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "decode_and_print(model, generation_config, sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f4020-83f4-4dd8-942f-5c3e0f739646",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb5bfe5-7968-4356-9a8e-f57e468cd2dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = False\n",
    "generation_config.num_beams = 1\n",
    "generation_config.max_new_tokens = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d72e195-676e-4b0d-ac19-58b3dcfdf19f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:695: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Budget Committee passed a spending bill. House Budget Committee passing a spendingBill. House budget Committee passed spending bill, passed bill. Bill passed by House Budget committee. House passed spending Bill. House passes spending bill; bill passed by Senate. House votes on bill. Senate votes on spending bill and passes bill.\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "decode_and_print(model, generation_config, sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a3d2b-5909-4165-8c7e-1aad48b906c9",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da6886-b273-4695-bc86-c352c0553f3d",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a2d8e-e79a-4945-bc74-0402b5b0b862",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fada6ee-2e3d-49fd-add6-bc5f75e019f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_sample\": true,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_new_tokens\": 150,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"top_k\": 10,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = True\n",
    "generation_config.num_beams = 1\n",
    "generation_config.temperature = 1\n",
    "\n",
    "print(generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5022f514-7cd4-4a64-bd8d-3ad420947ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top k  10\n",
      "House Budget Committee passed a spending bill. House Budget Committee pass a spending measure. House budget committee passed a bill to fund the government. House Speaker John Boehner says the bill is a way of funding the government and doesn't mean a huge increase. The spending bill would fund the U.S. government for the next five years.\n",
      "\n",
      "## Top k  20\n",
      "House Budget Committee passed a spending bill. House Budget Committee Passed a spending Act. House passed a bill to fund the government. House spent $1.1 billion on the budget. House budget committee voted down $200 million for the military. House vote on a spending plan to fund government.\n",
      "\n",
      "## Top k  30\n",
      "House Budget Committee passed a spending bill. House Budget CommitteePassed a spending legislation. House has yet to pass a budget. It would be the first time the House has passed a budget since 2010. It was the first vote since a failed effort in the spring to pass the spending bill in 2010.\n",
      "\n",
      "## Top k  40\n",
      "House Budget Committee passed a spending bill. House Budget Committee passes a spending Bill. House of Representatives passes a bill to fund the government. House votes to pass the bill. Republicans oppose the bill and say the spending bill will only make up $3.2 trillion. The bill passed with no Democratic support.\n",
      "\n",
      "## Top k  50\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spending legislation. House budget committee passed a bill to spend $400 billion. House committee passed bill without discussion. House panel didn't discuss whether the bill would include earmarks. House speaker said the bill did not address earmarks, as some had suggested.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "    \n",
    "    print(\"## Top k \", n*10)\n",
    "    generation_config.top_k = n*10\n",
    "    decode_and_print(model, generation_config, sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc19464-b352-425f-aec6-058f2368ce14",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Top-p sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6339d304-f3f5-4030-a8c0-8d41ccefbb30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_sample\": true,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_new_tokens\": 150,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"output_attentions\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = True\n",
    "generation_config.num_beams = 1\n",
    "generation_config.temperature = 1\n",
    "\n",
    "print(generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bbfdc15-58aa-4a98-b9f4-b35ded0673b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top p  0.15000000000000002\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spendingBill. House budget Committee passed spending bill, passed bill. Bill passed by House Budget committee. House passed spending Bill. House passes spending bill; bill passed by Senate. House pass spending bill with no amendments.\n",
      "\n",
      "## Top p  0.35000000000000003\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a spending bills. House budget committee passed a bill. Senate Budget Committee passes a spendingBill. House passes a bill to spend money. House passed a Spending Bill. House votes on the bill. Bill passes.\n",
      "\n",
      "## Top p  0.55\n",
      "House Budget Committee passed a spending bill. House Budget Committee Passed a spending Bill. House budget committee passed a bill. Senate Budget Committee passes a spending measure. Senate budget committee passes a bill with spending provisions. Senate passed a spend bill. The House budget bill passed. The Senate budget bill was passed.\n",
      "\n",
      "## Top p  0.75\n",
      "House Budget Committee passed a spending bill. House Budget Committee Passed a spendingBill. Houseudget Committee passed House Budget Bill. House Budget Committee passing a spending Bill. Second reading of bill passed. House passed bill. No votes on the bill. The bill goes to the Senate for consideration.\n",
      "\n",
      "## Top p  0.95\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House passed a bill that could be used as a framework for a spending measure for another decade. House Republicans want to extend the duration of the Affordable Care Act into fiscal year 2017, but also introduce a number of new spending cuts to keep the old ones in place. House has passed a law to fund the bill.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "    generation_config.top_p = 0.2*n-0.05\n",
    "    print(\"## Top p \", generation_config.top_p)\n",
    "    decode_and_print(model, generation_config, sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ccef8-2f34-471a-9f60-890c72c1bc29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97a6d9a9-e8e2-488d-b24c-3733b219c90c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "House Budget Committee passed a spending bill, and House Budget Committee also passed the Senate version. House Budget House passed spending bill. House Speaker Paul Ryan passes a spending measure. House has passed a budget. Speaker Ryan says they're going to pass a bill. In exchange, they say it's likely the President will increase the deficit by a few billion dollars.\n",
      "\n",
      "Output: \n",
      "House Budget Committee passed a spending bill. House Budget Committee pass a spendingBill. House Speaker John Boehner votes for spending bill to pass. House and Senate committees consider budgets for the fiscal year 2014-15, 2015-16. First approval of legislation necessary. Next item: Second passing a spending Bill.\n",
      "\n",
      "Output: \n",
      "House Budget Committee passed spending bill. House Budget Committeepassed bill with majority vote. House could pass new spending bill next week. House Speaker John Boehner says bill is just a start. They are all waiting for more money. That bill may be introduced again. They have not all voted on the bill yet, but are expected to.\n",
      "\n",
      "Output: \n",
      "House Budget Committee passed a spending bill. House Budget Committee has passed a bill to fund the government. House Speaker Paul Ryan passed a budget bill. He had asked Congress to consider a spending measure. House GOP said a bill wouldn't go into effect until the new spending bill was signed into law.\n",
      "\n",
      "Output: \n",
      "House Budget Committee passed a spending bill. House Budget Committee has already passed a budget. House will vote again on August 30. House passed a new spending bill on Tuesday. House Republicans plan to continue working on the budget until the Senate gets a chance to approve it. House Democrats wanted to work on a spending measure that would prevent the $80-$100 billion deficit being funded by the government. House Republican are set to vote on a larger spending bill next month.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "encoded_input_ids_1 = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids = encoded_input_ids_1,\n",
    "        num_return_sequences=5, \n",
    "        generation_config = generation_config,\n",
    "        return_dict_in_generate = True,\n",
    "        output_scores = True\n",
    "    )\n",
    "\n",
    "for s in generation_output.sequences:\n",
    "    print(\"Output: \")\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6c3e4-7906-4f55-ae6b-11fa4b7461e2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1217aadb-5d7f-4913-8796-8a564b0bb1a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill.'\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.do_sample = False\n",
    "generation_config.num_beams = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4271cf81-5c61-4914-931d-4f8de6ff441a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Beam size of  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Budget Committee passed a spending bill. House Budget Committee passing a spendingBill. House budget Committee passed spending bill, passed bill. Bill passed by House Budget committee. House passed spending Bill. House passes spending bill; bill passed by Senate. House votes on bill. Senate votes on spending bill and passes bill.\n",
      "\n",
      "## Beam size of  2\n",
      "House Budget Committee passed a spending bill. House Budget Committee passing a bill to fund the government. House budget committee passed a bill that would fund the U.S. government through 2018. House passed a budget bill that will fund the country's government through 2019. The bill was passed by the House of Representatives and the Senate.\n",
      "\n",
      "## Beam size of  3\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The bill was passed by the House of Representatives. The Senate will vote on the bill later this month. The spending bill is expected to be passed within the week.\n",
      "\n",
      "## Beam size of  4\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The spending bill was passed by the House of Representatives. The Senate will vote on the spending bill later this month. The bill is expected to be approved by the Senate on Thursday.\n",
      "\n",
      "## Beam size of  5\n",
      "House Budget Committee passes a spending bill. House Budget Committee passed a spending bills. House budget committee passed a bill to fund the government. The bill was passed by the House of Representatives. The Senate will vote on the bill later this month. The spending bill is expected to pass in the next few days.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "\n",
    "    print(\"## Beam size of \", n)\n",
    "    generation_config.num_beams = n\n",
    "    decode_and_print(model, generation_config, sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcae9c9-6f66-45f4-bb49-cac61ddd7b12",
   "metadata": {},
   "source": [
    "# Decoding with Constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69d88892-d8a0-4d62-88aa-77e5f61a1e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eabfdc2291e4534a007621a8fe19d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a7b69fe19f4b1398b4a4d5e4e147d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cuda.is_available: \t True\n",
      "cuda.device_count: \t 1\n",
      "cuda.current_device: \t 0\n",
      "cuda.device: \t\t <torch.cuda.device object at 0x7f0a80763260>\n",
      "\n",
      "cuda.get_device_name: \t NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "total memory: \t\t 4294508544\n",
      "reserved memory:\t 6794772480\n",
      "allocated memory:\t 178054144\n",
      "\n",
      "device name: \t\t cuda:0\n",
      "transformers: \t\t 4.47.0\n",
      "pytorch: \t\t 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import transformers\n",
    "import torch \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "def cuda_info():\n",
    "    print()\n",
    "    print(\"cuda.is_available: \\t\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda.device_count: \\t\", torch.cuda.device_count())\n",
    "        print(\"cuda.current_device: \\t\", torch.cuda.current_device())\n",
    "        print(\"cuda.device: \\t\\t\", torch.cuda.device(torch.cuda.current_device()))\n",
    "        print()\n",
    "        print(\"cuda.get_device_name: \\t\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "        print(\"total memory: \\t\\t\", torch.cuda.get_device_properties(0).total_memory)\n",
    "        print(\"reserved memory:\\t\", torch.cuda.memory_reserved(0))\n",
    "        print(\"allocated memory:\\t\", torch.cuda.memory_allocated(0))\n",
    "\n",
    "\n",
    "    device = \"cuda:\" + str(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\"\n",
    "    print()\n",
    "    print(\"device name: \\t\\t\", device)\n",
    "    print(\"transformers: \\t\\t\", transformers.__version__)\n",
    "    print(\"pytorch: \\t\\t\", torch.__version__)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "\n",
    "cuda_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b611331-7827-4639-a5a4-ea933cbc1a82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Repetitions and word lists\n",
    "### n-gram Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c17e212c-4890-4414-af02-5d212a6cad09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      "The House Budget Committee passed a spending bill on Thursday that would cut the deficit by $1.3 trillion over 10 years, or about 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The House Budget Committee passed a spending bill'\n",
    "\n",
    "encoded_input_ids_1 = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = model.generate(\n",
    "        input_ids = encoded_input_ids_1,\n",
    "        no_repeat_ngram_size=1,\n",
    "        return_dict_in_generate = True,\n",
    "        output_scores = True\n",
    "    )\n",
    "\n",
    "for s in generation_output.sequences:\n",
    "    print(\"Output: \")\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcee34b2-7507-4651-8417-b4de73dd4243",
   "metadata": {},
   "source": [
    "### Force words and bad words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e84aee2-504c-434c-9218-d74bc603dc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Force word ids:\n",
      "  DisjunctiveConstraint:  [[820, 734], [820, 530]]\n",
      "  PhrasalConstraint:  [47408, 783, 393, 4656]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The soldiers'\n",
    "input_ids = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "\n",
    "## Forced words\n",
    "force_disjunctive = [\"day two\", \"day one\"]\n",
    "force_phrasal = \"leave now or die\"\n",
    "\n",
    "force_words_ids = [ tokenizer(force_disjunctive, add_special_tokens=False).input_ids,\n",
    "                    tokenizer(force_phrasal, add_special_tokens=False).input_ids\n",
    "                  ]\n",
    "\n",
    "print(\"## Force word ids:\")\n",
    "for word_ids in force_words_ids:\n",
    "    if isinstance(word_ids[0], list):\n",
    "        print(\"  DisjunctiveConstraint: \", word_ids)\n",
    "    else:\n",
    "        print(\"  PhrasalConstraint: \", word_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e294ceb-129f-40de-9096-23fa7eb93dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Bad word ids:\n",
      "PhrasalConstraint:  [1929, 296]\n",
      "PhrasalConstraint:  [1941]\n"
     ]
    }
   ],
   "source": [
    "## Bad words\n",
    "bad_words_set = [\"whom\", \"year\"]\n",
    "bad_words_ids = tokenizer(bad_words_set, add_special_tokens=False).input_ids\n",
    "\n",
    "print(\"## Bad word ids:\")\n",
    "for word_ids in bad_words_ids:\n",
    "    if isinstance(word_ids[0], list):\n",
    "        print(\"DisjunctiveConstraint: \", word_ids)\n",
    "    else:\n",
    "        print(\"PhrasalConstraint: \", word_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb8db62e-f342-468d-b4c9-db59429b263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-cv-ir/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_scores` is. When `return_dict_in_generate` is not `True`, `output_scores` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Output: \n",
      "The soldiers in the field were not the only ones who were injured.\n",
      "\n",
      "day twoleave now or die\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generation_output = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    force_words_ids=force_words_ids,\n",
    "    bad_words_ids=bad_words_ids,\n",
    "    num_beams = 10,\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=6,\n",
    "    remove_invalid_values=True,\n",
    "    output_scores = True\n",
    ")\n",
    "\n",
    "for s in generation_output:\n",
    "    print(\"## Output: \")\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    print(output)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3f06a-aaa2-46b0-af95-fc7031f449f4",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef104a-de7d-433c-ac89-967ea5e8363a",
   "metadata": {},
   "source": [
    "### Phrasal Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bf0771b-150c-4264-8d7e-ed5394d6aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The soldiers, who had been stationed at the base, had been ordered to leave the area.\n",
      "\n",
      "The soldiers, who were stationedat the base\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PhrasalConstraint\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\").to(device)\n",
    "\n",
    "encoder_input_str = \"The soldiers\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "\n",
    "force_flexible_set = 'at the base'\n",
    "tk_list = tokenizer(force_flexible_set, add_special_tokens=False).input_ids\n",
    "\n",
    "constraints = [\n",
    "    PhrasalConstraint(tk_list)\n",
    "]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    constraints=constraints,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    no_repeat_ngram_size=5,\n",
    "    max_length = 30,\n",
    "    remove_invalid_values=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58b87d-0458-498a-a6fa-b7e9bc31e236",
   "metadata": {},
   "source": [
    "### Disjunctive Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6efa114c-a471-41e6-a7ff-0d36c49691a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25967], [3847]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PhrasalConstraint, DisjunctiveConstraint\n",
    "\n",
    "encoder_input_str = \"The soldiers\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "force_words_set1 = [\" stationed\", \"night\"]\n",
    "words_ids_set1 = tokenizer(force_words_set1, add_special_tokens=False).input_ids\n",
    "print(words_ids_set1)\n",
    "\n",
    "constraints = [\n",
    "    DisjunctiveConstraint(words_ids_set1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34642d97-d9a4-4a8e-8efc-6a443e5d0a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ġstationed'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(25967)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8da56ae7-5133-4c17-8c06-c5223b6304d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The soldiers, who had been stationed at the base, were taken to a nearby hospital, where they were treated for minor injuries and released.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    constraints=constraints,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    max_length = 30,\n",
    "    no_repeat_ngram_size=6,\n",
    "    remove_invalid_values=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f52bc5-0784-485c-a2f0-5715cecd59a3",
   "metadata": {},
   "source": [
    "### List of Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7df2be57-0be2-43ce-b6f0-d94e677c1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[' stationed', 'in the field']\n",
      "{25967: {}, 259: {262: {2214: {}}}}\n",
      "\n",
      "[' hospital']\n",
      "{4436: {}}\n",
      "\n",
      " at the battle\n",
      "[379, 262, 3344]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, PhrasalConstraint, DisjunctiveConstraint\n",
    "\n",
    "# The prompt\n",
    "encoder_input_str = \"The soldiers\"\n",
    "input_ids = tokenizer(encoder_input_str, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "# First constraint\n",
    "force_words_set1 = [\" stationed\", \"in the field\"]\n",
    "words_ids_set1 = tokenizer(force_words_set1, add_special_tokens=False).input_ids\n",
    "constraint_1 = DisjunctiveConstraint(words_ids_set1)\n",
    "\n",
    "print()\n",
    "print(force_words_set1)\n",
    "print(constraint_1.trie.trie)\n",
    "\n",
    "# Second constraint\n",
    "force_words_set2 = [\" hospital\"]\n",
    "words_ids_set2 = tokenizer(force_words_set2, add_special_tokens=False).input_ids\n",
    "constraint_2 = DisjunctiveConstraint(words_ids_set2)\n",
    "\n",
    "print()\n",
    "print(force_words_set2)\n",
    "print(constraint_2.trie.trie)\n",
    "\n",
    "# Third constraint\n",
    "force_flexible_set = \" at the battle\"\n",
    "phrasal_constraints = tokenizer(force_flexible_set, add_special_tokens=False).input_ids\n",
    "constraint_3 = PhrasalConstraint(phrasal_constraints)\n",
    "\n",
    "print()\n",
    "print(force_flexible_set)\n",
    "print(constraint_3.token_ids)\n",
    "\n",
    "# The list of constraints\n",
    "constraints = [ constraint_1, constraint_2,constraint_3 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7ebd77b-cea5-40b9-b112-db8e79853389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The soldiers stationed at the base were not allowed to leave the base until the end of the war.\n",
      "\n",
      "\"We were told at the battle hospital\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    constraints=constraints,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=1,\n",
    "    max_length = 30,\n",
    "    no_repeat_ngram_size=5,\n",
    "    remove_invalid_values=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-cv-ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
