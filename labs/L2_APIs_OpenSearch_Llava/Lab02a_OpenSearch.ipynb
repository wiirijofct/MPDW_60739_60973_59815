{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f15afcf-b8df-4dc4-b5bd-401ca429bdce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction to OpenSearch\n",
    "\n",
    "OpenSearch is search engine that nicely scales to billion size documents. Its indexes can be composed of multiple fields, each one indexing different parts of the documents. Each field has its own data type, e.g., text, keywords, numbers, knn-vectors. Text fields use a specific analyser and a retrieval model.\n",
    "\n",
    "A server is available on the cluster for this course. You can also set up your own server in your local machine. Docker is a convenient solution: https://opensearch.org/docs/latest/opensearch/install/docker/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74452b2-5e1a-4eb5-9cdd-fd9bc3a3603d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## OpenSearch connection settings\n",
    "\n",
    "For this course, a server is available on the cluster for this course. If you really need to you can set up your own server in your local machine. I advise you to use docker: https://opensearch.org/docs/latest/opensearch/install/docker/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccb245c-8503-4819-a30c-8ac9e9c6f8b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import requests\n",
    "\n",
    "host = 'api.novasearch.org'\n",
    "port = 443\n",
    "\n",
    "user = 'user08' # Add your user name here.\n",
    "password = '55LL.TTSS' # Add your user password here. For testing only. Don't store credentials in code. \n",
    "index_name = user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d725429",
   "metadata": {},
   "source": [
    "## On localhost server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab3b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import requests\n",
    "\n",
    "host = 'localhost'\n",
    "port = 9200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b4b34-d8bb-4915-ba1c-501fbba2c7fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## OpenSearch Python API \n",
    "\n",
    "OpenSearch communicates via REST which can be accessed with CURL (or its Python port, the requests library). For your conveninence we will use the Python client. A short introduction is available here:\n",
    "https://opensearch.org/docs/latest/clients/python/\n",
    "\n",
    "## Opening an Index\n",
    "The example below establishes a connection with the server and, if your index is already created, it displays the index settings, mappings and the number of indexed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b3f988-477d-4cb8-816b-70b230d7a55c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX SETTINGS\n",
      "{'user08': {'settings': {'index': {'creation_date': '1742992410788',\n",
      "                                   'knn': 'true',\n",
      "                                   'number_of_replicas': '0',\n",
      "                                   'number_of_shards': '4',\n",
      "                                   'provided_name': 'user08',\n",
      "                                   'refresh_interval': '1s',\n",
      "                                   'replication': {'type': 'DOCUMENT'},\n",
      "                                   'uuid': 'KWR4FZAkR6-DF1vn3EHOWw',\n",
      "                                   'version': {'created': '136387927'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX MAPPINGS\n",
      "{'user08': {'mappings': {'dynamic': 'strict',\n",
      "                         'properties': {'contents': {'analyzer': 'standard',\n",
      "                                                     'similarity': 'BM25',\n",
      "                                                     'type': 'text'},\n",
      "                                        'doc_id': {'type': 'keyword'},\n",
      "                                        'json': {'type': 'flat_object'},\n",
      "                                        'sentence_embedding': {'dimension': 768,\n",
      "                                                               'method': {'engine': 'faiss',\n",
      "                                                                          'name': 'hnsw',\n",
      "                                                                          'parameters': {'ef_construction': 256,\n",
      "                                                                                         'm': 48},\n",
      "                                                                          'space_type': 'innerproduct'},\n",
      "                                                               'type': 'knn_vector'},\n",
      "                                        'tags': {'type': 'keyword'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX #DOCs\n",
      "{'count': 2, '_shards': {'total': 4, 'successful': 4, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy import helpers\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = (user, password),\n",
    "    use_ssl = True,\n",
    "    url_prefix = 'opensearch_v2',\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False\n",
    ")\n",
    "\n",
    "if client.indices.exists(index_name):\n",
    "\n",
    "    resp = client.indices.open(index = index_name)\n",
    "    print(resp)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX SETTINGS')\n",
    "    settings = client.indices.get_settings(index = index_name)\n",
    "    pp.pprint(settings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX MAPPINGS')\n",
    "    mappings = client.indices.get_mapping(index = index_name)\n",
    "    pp.pprint(mappings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX #DOCs')\n",
    "    print(client.count(index = index_name))\n",
    "else:\n",
    "    print(\"Index does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20729f13",
   "metadata": {},
   "source": [
    "## On local server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5c13d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wiirijo/anaconda3/envs/mpdw/lib/python3.9/site-packages/opensearchpy/connection/http_urllib3.py:214: UserWarning: Connecting to https://localhost:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n",
      "/home/wiirijo/anaconda3/envs/mpdw/lib/python3.9/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "import pprint as pp\n",
    "\n",
    "# Define the connection to the local OpenSearch server\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_auth = ('admin', '.Wiirijo321'),  \n",
    "    http_compress = True,  # Enables gzip compression for request bodies\n",
    "    use_ssl = True,\n",
    "    verify_certs = False,\n",
    "    ssl_assert_hostname = False,\n",
    ")\n",
    "\n",
    "index_name = \"wiirijo\"  # Replace with your actual index name\n",
    "\n",
    "# Check if index exists\n",
    "if client.indices.exists(index=index_name):\n",
    "    resp = client.indices.open(index=index_name)\n",
    "    print(resp)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX SETTINGS')\n",
    "    settings = client.indices.get_settings(index=index_name)\n",
    "    pp.pprint(settings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX MAPPINGS')\n",
    "    mappings = client.indices.get_mapping(index=index_name)\n",
    "    pp.pprint(mappings)\n",
    "\n",
    "    print('\\n----------------------------------------------------------------------------------- INDEX #DOCs')\n",
    "    print(client.count(index=index_name))\n",
    "else:\n",
    "    print(\"Index does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdef48c-21cf-4869-9aa8-64788c610740",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Closing a Index\n",
    "To release resources in the OpenSearch server you should always close the index handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29117f92-f724-4fe4-a148-cf19b56dd53a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resp = client.indices.close(index = index_name)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec20622-378e-43a1-8603-02b3eaf1df90",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Index creation and configuration\n",
    "In this section we will see how to create an index, inspect the configuration and delete an index if needed.\n",
    "\n",
    "## Create an index with your own settings\n",
    "\n",
    "Lets first create an index distributed across 4 shards, no replicas, and with support for knn-vector data types. In terms of indexed data, we define two data properties: doc_id and contents, with data types keyword and text respectively.\n",
    "\n",
    "Property type | Description\n",
    "-----|-----\n",
    "text|A string sequence of characters that represent full-text values.\n",
    "keyword|A string sequence of structured characters, such as an email or ZIP code.\n",
    "boolean|OpenSearch accepts true and false as boolean values. An empty string is equal to false. \n",
    "integer|A signed 32-bit number. \n",
    "float|A single-precision 32-bit floating point number. \n",
    "double|A double-precision 64-bit floating point number.\n",
    "date|if new string fields match a dateâ€™s format, then the string is processed as a date field. For example, date: \"2012/03/11\" is processed as a date.\n",
    "objects|Objects are standard JSON objects, which can have fields and mappings of their own. For example, a movies object can have additional properties such as title, year, and director.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06559069-2ee1-4c20-ac09-802fd65bdd45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "index_body = {\n",
    "   \"settings\":{\n",
    "      \"index\":{\n",
    "         \"number_of_replicas\":0,\n",
    "         \"number_of_shards\":4,\n",
    "         \"refresh_interval\":\"-1\",\n",
    "         \"knn\":\"true\"\n",
    "      }\n",
    "   },\n",
    "   \"mappings\":{\n",
    "       \"dynamic\":      \"strict\",\n",
    "       \"properties\":{\n",
    "         \"doc_id\":{\n",
    "            \"type\":\"keyword\"\n",
    "         },\n",
    "         \"tags\":{\n",
    "            \"type\":\"keyword\"\n",
    "         },\n",
    "         \"json\":{\n",
    "            \"type\":\"flat_object\"\n",
    "         },\n",
    "         \"contents\":{\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\":\"standard\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    print(\"Index already existed. Nothing to be done.\")\n",
    "else:        \n",
    "    response = client.indices.create(index_name, body=index_body)\n",
    "    print('\\nCreating index:')\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926fc1ba-4906-460e-9c35-926acf3d24ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check the indexes, settings and mappings\n",
    "Once you create an index, you should verify that it is created according to your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd4df4-5a77-44fd-b62e-b3dcac013e62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\n----------------------------------------------------------------------------------- INDEX SETTINGS')\n",
    "index_settings = {\n",
    "    \"settings\":{\n",
    "      \"index\":{\n",
    "         \"refresh_interval\" : \"1s\"\n",
    "      }\n",
    "   }\n",
    "}\n",
    "pp.pprint(client.indices.get_alias(\"*\"))\n",
    "\n",
    "client.indices.put_settings(index = index_name, body = index_settings)\n",
    "settings = client.indices.get_settings(index = index_name)\n",
    "pp.pprint(settings)\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------------- INDEX MAPPINGS')\n",
    "mappings = client.indices.get_mapping(index = index_name)\n",
    "pp.pprint(mappings)\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------------- INDEX #DOCs')\n",
    "print(client.count(index = index_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c8045-9117-4e45-831d-dd52b4b69581",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Index deletion\n",
    "Be absolutely sure tha you want to delete the index. There is no way of recovering it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd757fe9-d568-4ed8-84cf-76e568a7e3bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "This line is here to prevent you from inadvertently deleting data.\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index.\n",
    "    response = client.indices.delete(\n",
    "        index = index_name\n",
    "    )\n",
    "    print('\\nDeleting index:')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32f953-2533-4e93-a7c0-4a0470e1f32c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Document processing and indexing\n",
    "\n",
    "## Built-in document tokenizers and analyzers\n",
    "\n",
    "The built-in tokenizers and analyzers include: standard, simple, whitespace, stop, keyword, pattern, [language], fingerprint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab482d99-c852-44e8-a79e-8bd2cadf31c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "anls = {\n",
    "  \"analyzer\": \"whitespace\",\n",
    "  \"text\": \"the quick brown fox\"\n",
    "}\n",
    "client.indices.analyze(body=anls, index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db291d-f75b-4dd4-8256-757053b4cf4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "anls = {\n",
    "  \"analyzer\": \"standard\",\n",
    "  \"text\": \"the quick brown fox\"\n",
    "}\n",
    "client.indices.analyze(body=anls, index=index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ab7be-314f-453d-b566-534e7c04e338",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Simple document indexing\n",
    "\n",
    "You can index documents in OpenSearch by adding one document at a time. This is done with JSON data as follows. Note that the id parameter in the API call is the unique identifier, which works as a key.\n",
    "\n",
    "If you add one document that already exists in the index, it will update the data. You can update only part of the fields and leave all the others unchanged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de6117-04a3-4eb0-b182-fcc66fed830e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "dd = '{\"name\":\"John\", \"age\":30, \"car\":null}'\n",
    "doc = {\n",
    "    'doc_id': 'documentA',\n",
    "    'tags': ['red', 'blue'],\n",
    "    'jsons': dd,\n",
    "    'contents': docs[0]\n",
    "}\n",
    "resp = client.index(index=index_name, id=1, body=doc)\n",
    "print(resp['result'])\n",
    "\n",
    "doc = {\n",
    "    'doc_id': 'documentB',\n",
    "    'tags': ['red'],\n",
    "    'jsons': dd,\n",
    "    'contents': docs[1]\n",
    "}\n",
    "resp = client.index(index=index_name, id=2, body=doc)\n",
    "print(resp['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c36e16-5fd4-4c6e-806a-30a1bac5ee46",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deleting a single document\n",
    "Similarly, you can delete one document at a time as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04018f-2ed8-49c0-a901-d4d9877a8988",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "This line is here to prevent you from inadvertently deleting data.\n",
    "\n",
    "response = client.delete(\n",
    "    index = index_name,\n",
    "    id = id\n",
    ")\n",
    "\n",
    "print('\\nDeleting document:')\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db83cf-94fd-4416-8438-3d15f2899928",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Search methods\n",
    "\n",
    "OpenSearch supports many different search methods and has its own Query Syntax Language covering a wide range of search opts://opensearch.org/docs/latest/opensearch/query-dsl/index/\n",
    "\n",
    "## Text-based search\n",
    "\n",
    "OpenSearch is one of the best solutions for searching text. The text-based search documentation is available here:\n",
    "\n",
    "https://opensearch.org/docs/latest/opensearch/query-dsl/full-text/\n",
    "\n",
    "In the example below the 'query'  parameter indicates the search query, the 'size' parameter indicates the number of documents to be returned, the parametner 'source' indicates which fields should be returned in the search results, and the 'fields' parameter indicates the list of fields to be searched. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a2e93-3f41-4ac7-b2cd-84b66f999597",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5beaf96-5c80-4853-a7ac-20784a633f7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qtxt = \"How many people live in London?\"\n",
    "\n",
    "query_bm25 = {\n",
    "  'size': 5,\n",
    "  '_source': ['_tags'],\n",
    "#  '_source': ['doc_id'],\n",
    "#  '_source': '',\n",
    "  'query': {\n",
    "    'multi_match': {\n",
    "      'query': qtxt,\n",
    "      'fields': ['contents']\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c209dd3-9ee3-4eed-86aa-64f14d9f2ec3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Term queries\n",
    "\n",
    "https://opensearch.org/docs/latest/opensearch/query-dsl/term/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd4f52-56f5-4940-a152-4bc9914c3fdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qtxt = \"How many people live in London?\"\n",
    "\n",
    "query_bm25 = {\n",
    "  'size': 5,\n",
    "  '_source': ['contents'],\n",
    "  'query': {\n",
    "        \"term\": {\n",
    "            \"tags\" : 'red'\n",
    "        }\n",
    "   }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c4573-1bd0-471a-ad6d-b51c85b0498f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Boolean queries\n",
    "\n",
    "https://opensearch.org/docs/latest/opensearch/query-dsl/bool/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16eb60-d108-4266-82ab-d9b762f3d809",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qtxt = \"How many people live in London?\"\n",
    "\n",
    "query_bm25 = {\n",
    "  'size': 5,\n",
    "  '_source': ['contents'],\n",
    "#  '_source': ['doc_id'],\n",
    "#  '_source': '',\n",
    "  'query': {\n",
    "      'bool':{\n",
    "          \"must\":{\n",
    "            \"term\": {\n",
    "                \"tags\" : 'red'\n",
    "            }\n",
    "          },\n",
    "          \"should\": \n",
    "        {\n",
    "            'multi_match': {\n",
    "              'query': qtxt,\n",
    "              'fields': ['contents']\n",
    "            }\n",
    "        }\n",
    "      }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_bm25,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baddea7-76ac-47b0-b071-250cb7014c9f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Vector search and semantic embeddings\n",
    "\n",
    "## Create an index with dense vectors\n",
    "\n",
    "To create the dense vector field you can use the configuration provided below. The 'dimension' property indicates the dimensionality of the indexed vectors, the 'space_type' indicates similarity function, and the parameters are specific to the indexing method, the 'hnsw' (Hierarichical Navigable Small World).\n",
    "\n",
    "For details see the documentation:\n",
    "- https://opensearch.org/docs/latest/search-plugins/knn/approximate-knn/\n",
    "- https://opensearch.org/docs/latest/search-plugins/knn/knn-index#method-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a8f5c-a6df-4b5a-ba88-55dafba4682f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_body = {\n",
    "   \"settings\":{\n",
    "      \"index\":{\n",
    "         \"number_of_replicas\":0,\n",
    "         \"number_of_shards\":4,\n",
    "         \"refresh_interval\":\"-1\",\n",
    "         \"knn\":\"true\"\n",
    "      }\n",
    "   },    \n",
    "   \"mappings\":{\n",
    "      \"dynamic\":      \"strict\",\n",
    "      \"properties\":{\n",
    "         \"doc_id\":{\n",
    "            \"type\":\"keyword\"\n",
    "         },\n",
    "         \"contents\":{\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\": \"standard\",\n",
    "#            \"analyzer\":\"my_analyzer\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         },\n",
    "         \"sentence_embedding\":{\n",
    "            \"type\":\"knn_vector\",\n",
    "            \"dimension\": 768,\n",
    "            \"method\":{\n",
    "               \"name\":\"hnsw\",\n",
    "               \"space_type\":\"innerproduct\",\n",
    "               \"engine\":\"faiss\",\n",
    "               \"parameters\":{\n",
    "                  \"ef_construction\":256,\n",
    "                  \"m\":48\n",
    "               }\n",
    "            }\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    print(\"Index already existed. You may force the new mappings.\")\n",
    "else:        \n",
    "    response = client.indices.create(index_name, body=index_body)\n",
    "    print('\\nCreating index:')\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ace82-ea25-4603-a69b-cf819e620283",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dual-Encoders\n",
    "\n",
    "To compute the embedding vectors of each document, we can use the Transformer encodres trained in the MSMARCO Dataset. There are many other models available in the HuggingFace repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28536391-5b9b-41b9-897b-6e353fd0c6f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take average of all tokens\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "doc_emb = encode(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea19c55-e60f-4c3e-8444-a9837cbf1e94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Indexing document embedding vectors\n",
    "\n",
    "In the previous step we saw how to compute the embedding representation of a document. You can index document embeddings in OpenSearch by adding a new field to your JSON file as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f4b3b-a06f-4654-8985-23c51d5bb6a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "doc = {\n",
    "    'doc_id': 'documentA',\n",
    "    'contents': docs[0],\n",
    "    'sentence_embedding': doc_emb[0].numpy()\n",
    "}\n",
    "resp = client.index(index=index_name, id=1, body=doc)\n",
    "print(resp['result'])\n",
    "\n",
    "doc = {\n",
    "    'doc_id': 'documentB',\n",
    "    'contents': docs[1],\n",
    "    'sentence_embedding': doc_emb[1].numpy()\n",
    "}\n",
    "resp = client.index(index=index_name, id=2, body=doc)\n",
    "print(resp['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df3cb7-927f-40ac-9b46-a75e4fc9a9c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Embedding spaces search\n",
    "\n",
    "Similarly, you need to compute the embedding representation of the query and submit it in the search query as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2f2bf-7513-46cc-8dc1-4e7acbf4bf5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the query embedding\n",
    "query = \"How many people live in London?\"\n",
    "query_emb = encode(query)\n",
    "\n",
    "query_denc = {\n",
    "  'size': 5,\n",
    "#  '_source': ['doc_id', 'contents', 'sentence_embedding'],\n",
    "#  '_source': ['doc_id', 'contents'],\n",
    "  '_source': ['doc_id'],\n",
    "   \"query\": {\n",
    "        \"knn\": {\n",
    "          \"sentence_embedding\": {\n",
    "            \"vector\": query_emb[0].numpy(),\n",
    "            \"k\": 2\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    body = query_denc,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "print('\\nSearch results:')\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e7503-ad00-4660-80bc-ab3d19767f94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training dual-encoders\n",
    "\n",
    "You can fine-tune dual-encoders in your domain data and get some extra points out of your search architecture.\n",
    "\n",
    "      https://www.sbert.net/docs/training/overview.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3147e3-d12b-49de-a424-52c6e46adcc1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Define the model. Either from scratch of by loading a pre-trained model\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "#Define your train examples. You need more than just two examples...\n",
    "train_examples = [InputExample(texts=['My first sentence', 'My second sentence'], label=0.8),\n",
    "    InputExample(texts=['Another pair', 'Unrelated sentence'], label=0.3)]\n",
    "\n",
    "#Define your train dataset, the dataloader and the train loss\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "#Tune the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafcf2d6-ce0a-499e-a4cf-f5831b8f1bdf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Specialized document analyzers\n",
    "Text data can be represented in different ways. In this section we will see different ways of transforming natural language documents into a computational representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952cf50-2bc1-464a-a4e1-5f6374ceb9c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create an index with specific analyzers\n",
    "The built-in analyzers offer a wide range of text processing methods. Each field can have its own analyzer and users can also define their own analyzers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50aa7b-f26b-4922-b9d7-671b1a631f19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "index_body = {\n",
    "   \"settings\":{\n",
    "      \"index\":{\n",
    "         \"number_of_replicas\":0,\n",
    "         \"number_of_shards\":4,\n",
    "         \"refresh_interval\":\"-1\",\n",
    "         \"knn\":\"true\"\n",
    "      },\n",
    "      \"analysis\":{\n",
    "         \"filter\":{\n",
    "            \"edge_ngram_filter\":{\n",
    "               \"type\":\"edge_ngram\",\n",
    "               \"min_gram\":1,\n",
    "               \"max_gram\":20\n",
    "            }\n",
    "         },\n",
    "         \"analyzer\":{\n",
    "            \"my_analyzer\":{\n",
    "               \"type\":\"custom\",\n",
    "               \"tokenizer\":\"standard\",\n",
    "               \"filter\":[\n",
    "                  \"lowercase\",\n",
    "                  \"edge_ngram_filter\"\n",
    "               ]\n",
    "            }\n",
    "         }\n",
    "      }\n",
    "   },\n",
    "   \"mappings\":{\n",
    "      \"properties\":{\n",
    "         \"doc_id\":{\n",
    "            \"type\":\"keyword\"\n",
    "         },\n",
    "         \"contents\":{\n",
    "            \"type\":\"text\",\n",
    "            \"analyzer\":\"my_analyzer\",\n",
    "            \"similarity\":\"BM25\"\n",
    "         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    print(\"Index already existed. Nothing to be done.\")\n",
    "else:        \n",
    "    response = client.indices.create(index_name, body=index_body)\n",
    "    print('\\nCreating index:')\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fe12f-bea1-40a2-9e70-337108a38038",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Spacy: Tokens, lemmas and POS\n",
    "If the built-in text processing methods are not sufficient for your problem, you can use external libraries like Spacy to extract other representations of text, such as POS and lemmas, or to use other stemmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fa007-c5f2-4a22-bee0-61d84eafc932",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "save_figures = False\n",
    "\n",
    "print(\"token\".ljust(10), \"lemma\".ljust(10), \"pos\".ljust(6), \"tag\".ljust(6), \"dep\".ljust(10),\n",
    "            \"shape\".ljust(10), \"alpha\", \"stop\")\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "for token in doc:\n",
    "    print(token.text.ljust(10), token.lemma_.ljust(10), token.pos_.ljust(6), token.tag_.ljust(6), token.dep_.ljust(10),\n",
    "            token.shape_.ljust(10), token.is_alpha, token.is_stop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef39997-8165-4514-9fd5-9716f15893eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Named entity recognition\n",
    "Spacy also identifies the mentions of relevant named entities. This can have a number of applications, such as selecting the documents that mention a given named entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287df26e-fe92-438c-89ad-15f409a8e7d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text.ljust(12), ent.label_.ljust(10), ent.start_char, ent.end_char)\n",
    "\n",
    "html_ent = displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpdw",
   "language": "python",
   "name": "mpdw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
